# processsing.py
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import os
from datetime import datetime
import re
import numpy as np
import random

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∫—É—Ä—Å–æ–≤
_CURRENCY_RATES_CACHE = None


def get_currency_rates(rates_file='/home/vulcan4ik/dashboard-cruise-app/app_data/currency_rates_2024-2025.csv'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    global _CURRENCY_RATES_CACHE

    if _CURRENCY_RATES_CACHE is not None:
        return _CURRENCY_RATES_CACHE

    try:
        rates_df = pd.read_csv(rates_file)
        rates_df['date'] = pd.to_datetime(rates_df['date'])
        _CURRENCY_RATES_CACHE = rates_df
        print(f"‚úÖ –ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(rates_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –∫—É—Ä—Å–æ–≤: {rates_df['date'].min()} - {rates_df['date'].max()}")
        return rates_df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç: {e}")
        return None


def convert_to_rub(row, rates_df):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—É–º–º—É –≤ —Ä—É–±–ª–∏ —Å —É—á–µ—Ç–æ–º –∫—É—Ä—Å–∞ –¶–ë + 4.5%"""

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—É–º–º—ã
    if pd.isna(row.get('amount_to_pay')) or row['amount_to_pay'] in [0, '', None]:
        return 0

    amount = float(row['amount_to_pay'])
    currency = str(row.get('currency', '—Ä–±')).strip()

    # –ú–∞–ø–ø–∏–Ω–≥ –≤–∞–ª—é—Ç
    currency_map = {
        'E': 'EUR',
        'EUR': 'EUR',
        '‚Ç¨': 'EUR',
        '$': 'USD',
        'USD': 'USD',
        '—Ä–±': 'RUB',
        'RUB': 'RUB',
        '—Ä—É–±': 'RUB'
    }

    target_currency = currency_map.get(currency, 'RUB')

    # –ï—Å–ª–∏ —Ä—É–±–ª–∏ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if target_currency == 'RUB':
        return round(amount, 2)

    # –î–ª—è –≤–∞–ª—é—Ç—ã –Ω—É–∂–Ω–∞ –¥–∞—Ç–∞ –∏ –∫—É—Ä—Å
    creation_date = row.get('creation_date')

    if rates_df is None or pd.isna(creation_date):
        print(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: –≤–∞–ª—é—Ç–∞={currency}, –¥–∞—Ç–∞={creation_date}")
        return 0

    try:
        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é –ø—Ä–µ–¥—ã–¥—É—â—É—é –¥–∞—Ç—É —Å –∫—É—Ä—Å–æ–º
        creation_date = pd.to_datetime(creation_date)
        available_dates = rates_df[rates_df['date'] <= creation_date]

        if available_dates.empty:
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ —Ä–∞–Ω—å—à–µ –≤—Å–µ—Ö –∫—É—Ä—Å–æ–≤ - –±–µ—Ä–µ–º —Å–∞–º—ã–π —Ä–∞–Ω–Ω–∏–π –∫—É—Ä—Å
            rate_row = rates_df.iloc[0]
            print(f"‚ö†Ô∏è –î–∞—Ç–∞ {creation_date.date()} —Ä–∞–Ω—å—à–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫—É—Ä—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º {rate_row['date'].date()}")
        else:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫—É—Ä—Å –¥–æ –¥–∞—Ç—ã —Å–æ–∑–¥–∞–Ω–∏—è
            rate_row = available_dates.iloc[-1]

        if target_currency in rate_row:
            rate = float(rate_row[target_currency])
            # –ö—É—Ä—Å –¶–ë + 4.5% –Ω–∞—Ü–µ–Ω–∫–∞
            converted_amount = (amount * rate) * 1.045
            return round(converted_amount, 2)
        else:
            print(f"‚ùå –í–∞–ª—é—Ç–∞ {target_currency} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—É—Ä—Å–∞—Ö")
            return 0

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–ª—è —Å—Ç—Ä–æ–∫–∏: {e}")
        return 0

def clean_numeric_data(df):
    """–û—á–∏—â–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –∑–∞–ø—è—Ç—ã—Ö –∏ –¥—Ä—É–≥–∏—Ö –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""

    def convert_numeric_value(x):
        if pd.isna(x) or x == '':
            return x

        str_val = str(x).strip()

        # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç—ã—Å—è—á)
        cleaned = str_val.replace(',', '')

        try:
            return float(cleaned)
        except ValueError:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return x

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –≤—Å–µ–º —Å—Ç–æ–ª–±—Ü–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —á–∏—Å–ª–æ–≤—ã–µ
    for column in df.columns:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–ø—è—Ç—ã–º–∏
        has_commas = df[column].apply(lambda x: ',' in str(x) if pd.notna(x) else False).any()

        if has_commas:
            df[column] = df[column].apply(convert_numeric_value)

    return df



def process_data(file_path):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""

    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    if file_path.endswith('.csv'):
        df = pd.read_csv(file_path)
    else:
        df = pd.read_excel(file_path)


    df = rename_columns(df)         #  –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
    df = clean_numeric_data(df)     #  –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    df = clean_data(df)             #  –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    df = fill_missing_buyer_names(df)  # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∞–≥–µ–Ω—Ç—Å—Ç–≤
    df = generate_amount_data(df)   #  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å—É–º–º—ã
    df = generate_payment_data(df)  #  –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–ª–∞—Ç—ã
    df = enrich_data(df)            #  –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏

    return df

def rename_columns(df):
    """–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ª–æ–≤–∞—Ä—é"""
    rename_dict = {
        '–ü—É—Ç–µ–≤–∫–∞': 'voucher_id',
        '–°—Ç—Ä–∞–Ω–∞': 'country',
        '–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è': 'creation_date',
        '–î–∞—Ç–∞ –∑–∞–µ–∑–¥–∞': 'checkin_date',
        '–î–Ω–µ–π': 'days',
        '–ß–µ–ª–æ–≤–µ–∫': 'people',
        '–°—Ç–∞—Ç—É—Å –ø—É—Ç–µ–≤–∫–∏': 'voucher_status',
        '–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å—Ç–∞—Ç—É—Å': 'internal_status',
        '–í–∞–ª—é—Ç–∞': 'currency',
        '–°—É–º–º–∞ –∫ –æ–ø–ª–∞—Ç–µ': 'amount_to_pay',
        '–û–ø–ª–∞—Ç–∞': 'payment',
        '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—É—Ä–∞': 'tour_name',
        '–ü–æ–∫—É–ø–∞—Ç–µ–ª—å: –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ': 'buyer_department',
        '–ü–æ–∫—É–ø–∞—Ç–µ–ª—å: –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'buyer_name',
        '–ü–æ–∫—É–ø–∞—Ç–µ–ª—å: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¢–ê': 'buyer_category',
        '–°–æ–∑–¥–∞—Ç–µ–ª—å': 'creator',
        '–í–µ–¥—É—â–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä': 'manager'
    }
    
    # –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º - pandas –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã
    df = df.rename(columns=rename_dict)

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è (—Ç–µ –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è)
    final_columns = [v for v in rename_dict.values() if v in df.columns]
    df = df[final_columns]

    print(f"‚úÖ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(final_columns)}")
    print(f"üìã –ò—Ç–æ–≥–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")

    return df




def clean_data(df):
    """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print(f" –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    required_columns = ['voucher_id', 'voucher_status']
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing_cols}")
        return df
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏/–∞–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—É—Ç–µ–≤–∫–∞–º–∏
    if 'voucher_status' in df.columns:
        df = df[~df['voucher_status'].isin(['–£–¥–∞–ª–µ–Ω', '–ê–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω', '—É–¥–∞–ª–µ–Ω','–∞–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω'])]
        print(f"üîç –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –∞–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö/—É–¥–∞–ª–µ–Ω–Ω—ã—Ö: {df.shape}")
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º voucher_id
    if 'voucher_id' in df.columns:
        initial_count = len(df)
        non_empty_mask = (
            df['voucher_id'].notna() &
            (df['voucher_id'] != '') &
            (df['voucher_id'].astype(str).str.strip() != '')
        )
        df = df[non_empty_mask]
        removed_count = initial_count - len(df)
        if removed_count > 0:
            print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º voucher_id: {removed_count}")
    
    # –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –≤–∞–∂–Ω—ã—Ö –ø–æ–ª—è—Ö
    important_fields = ['buyer_department', 'buyer_name', 'manager']
    for field in important_fields:
        if field in df.columns:
            missing_count = df[field].isna().sum()
            empty_count = (df[field] == '').sum()
            if missing_count > 0 or empty_count > 0:
                print(f"‚ö†Ô∏è –ü–æ–ª–µ '{field}': {missing_count} NaN, {empty_count} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")
    
    print(f"üìä –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
    return df
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    # df = df.fillna({
    #      'amount_to_pay': 0,
    #      'payment': 0,
    #      'people': 1,
    #      'days': 0
    #  })


# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Å—É–º–º–∞—Ö –∫ –æ–ø–ª–∞—Ç–µ
def generate_amount_data(df):
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if df['amount_to_pay'].notna().sum() > 0:
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        existing_amounts = df['amount_to_pay'].dropna()
        mean_amount = existing_amounts.mean()
        std_amount = existing_amounts.std()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        missing_mask = df['amount_to_pay'].isna()
        n_missing = missing_mask.sum()
        generated_amounts = np.random.normal(mean_amount, std_amount, n_missing)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (–Ω–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ, –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ)
        generated_amounts = np.clip(generated_amounts, 1000, 500000)
        df.loc[missing_mask, 'amount_to_pay'] = generated_amounts.round(2)
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–¥—Ä–∞–≤–æ–≥–æ —Å–º—ã—Å–ª–∞
        missing_mask = df['amount_to_pay'].isna()
        n_missing = missing_mask.sum()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—É–º–º—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π –∏ –ª—é–¥–µ–π
        base_amounts = []
        for idx in df[missing_mask].index:
            days = df.loc[idx, 'days']
            people = df.loc[idx, 'people']
            if pd.notna(days) and pd.notna(people):
                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ª–æ–≥–∏–∫–∞: –±–∞–∑–æ–≤—ã–π —Ç–∞—Ä–∏—Ñ + —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ –¥–µ–Ω—å –∏ —á–µ–ª–æ–≤–µ–∫–∞
                base = 5000 + (days * people * 1500)
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
                base *= random.uniform(0.8, 1.5)
            else:
                base = random.randint(10000, 200000)
            base_amounts.append(base)

        df.loc[missing_mask, 'amount_to_pay'] = [round(x, 2) for x in base_amounts]

    return df

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø–ª–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É–º–º –∫ –æ–ø–ª–∞—Ç–µ
def generate_payment_data(df):
    missing_payment_mask = df['payment'].isna()

    for idx in df[missing_payment_mask].index:
        amount = df.loc[idx, 'amount_to_pay']
        if pd.notna(amount):
            # –û–ø–ª–∞—Ç–∞ –æ–±—ã—á–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–∞ —Å—É–º–º–µ –∫ –æ–ø–ª–∞—Ç–µ
            # (–º–æ–≥—É—Ç –±—ã—Ç—å —Å–∫–∏–¥–∫–∏, —á–∞—Å—Ç–∏—á–Ω—ã–µ –æ–ø–ª–∞—Ç—ã –∏ —Ç.–¥.)
            payment = amount * random.uniform(0.7, 1.0)
            df.loc[idx, 'payment'] = round(payment, 2)
        else:
            df.loc[idx, 'payment'] = round(random.uniform(5000, 150000), 2)

    return df


def extract_region(agency_name):
    if not isinstance(agency_name, str) or agency_name.strip() == '' or agency_name.lower() in ['n/a', 'nan', 'none']:
        return '–ù–µ —É–∫–∞–∑–∞–Ω–æ'

    text = agency_name.strip()

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
    known_cities = {
        '–ú–æ—Å–∫–≤–∞': ['–º–æ—Å–∫–≤–∞', '–º—Å–∫', 'moscow'],
        '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥': ['—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥', '—Å–ø–±', '–ø–∏—Ç–µ—Ä', 'st. petersburg', 'petersburg'],
        '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫': ['–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–Ω–æ–≤–æ—Å–∏–±'],
        '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥': ['–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–µ–∫–±'],
        '–ö–∞–∑–∞–Ω—å': ['–∫–∞–∑–∞–Ω—å', 'kazan'],
        '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä': ['–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä'],
        '–ü–µ—Ä–º—å': ['–ø–µ—Ä–º—å', 'perm'],
        '–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É': ['—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É', '—Ä–æ—Å—Ç–æ–≤'],
        '–¢—é–º–µ–Ω—å': ['—Ç—é–º–µ–Ω—å'],
        '–ë–∞—Ä–Ω–∞—É–ª': ['–±–∞—Ä–Ω–∞—É–ª'],
        '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫': ['–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫'],
        '–í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫': ['–≤–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫', 'vladivostok'],
        '–°–∞–º–∞—Ä–∞': ['—Å–∞–º–∞—Ä–∞', 'samara'],
        '–ú–∏–Ω—Å–∫': ['–º–∏–Ω—Å–∫', 'minsk'],
        '–ë–∏—à–∫–µ–∫': ['–±–∏—à–∫–µ–∫', 'bishkek'],
        '–ê—Å—Ç–∞–Ω–∞': ['–∞—Å—Ç–∞–Ω–∞', 'astana'],
        '–°–æ—á–∏': ['—Å–æ—á–∏', 'sochi'],
        '–Ø—Ä–æ—Å–ª–∞–≤–ª—å': ['—è—Ä–æ—Å–ª–∞–≤–ª—å'],
        '–í–æ—Ä–æ–Ω–µ–∂': ['–≤–æ—Ä–æ–Ω–µ–∂'],
        '–ò—Ä–∫—É—Ç—Å–∫': ['–∏—Ä–∫—É—Ç—Å–∫'],
        '–•–∞–±–∞—Ä–æ–≤—Å–∫': ['—Ö–∞–±–∞—Ä–æ–≤—Å–∫'],
        '–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å': ['—Å—Ç–∞–≤—Ä–æ–ø–æ–ª—å'],
        '–ß–µ–ª—è–±–∏–Ω—Å–∫': ['—á–µ–ª—è–±–∏–Ω—Å–∫'],
        '–ù–æ–≤–æ—Ä–æ—Å—Å–∏–π—Å–∫': ['–Ω–æ–≤–æ—Ä–æ—Å—Å–∏–π—Å–∫'],
        '–¢–æ–º—Å–∫': ['—Ç–æ–º—Å–∫'],
        '–ö–∏–µ–≤': ['–∫–∏–µ–≤', 'kyiv'],
        '–¢–∞—à–∫–µ–Ω—Ç': ['—Ç–∞—à–∫–µ–Ω—Ç', 'tashkent'],
        '–ï—Ä–µ–≤–∞–Ω': ['–µ—Ä–µ–≤–∞–Ω', 'yerevan'],
        '–ë–∞–∫—É': ['–±–∞–∫—É', 'baku'],
        '–ê–ª–º–∞—Ç—ã': ['–∞–ª–º–∞—Ç—ã', 'almaty'],
        '–û–º—Å–∫': ['–æ–º—Å–∫'],
        '–£—Ñ–∞': ['—É—Ñ–∞'],
        '–í–æ–ª–≥–æ–≥—Ä–∞–¥': ['–≤–æ–ª–≥–æ–≥—Ä–∞–¥'],
        '–ö–µ–º–µ—Ä–æ–≤–æ': ['–∫–µ–º–µ—Ä–æ–≤–æ'],
        '–û—Ä—ë–ª': ['–æ—Ä—ë–ª', '–æ—Ä–µ–ª'],
        '–õ–∏–ø–µ—Ü–∫': ['–ª–∏–ø–µ—Ü–∫'],
        '–ö–æ—Å—Ç—Ä–æ–º–∞': ['–∫–æ—Å—Ç—Ä–æ–º–∞'],
        '–Ø–∫—É—Ç—Å–∫': ['—è–∫—É—Ç—Å–∫', 'yakutsk'],
        '–ü–µ—Ç—Ä–æ–∑–∞–≤–æ–¥—Å–∫': ['–ø–µ—Ç—Ä–æ–∑–∞–≤–æ–¥—Å–∫'],
        '–Æ–∂–Ω–æ-–°–∞—Ö–∞–ª–∏–Ω—Å–∫': ['—é–∂–Ω–æ-—Å–∞—Ö–∞–ª–∏–Ω—Å–∫'],
        '–•–∏–º–∫–∏': ['—Ö–∏–º–∫–∏'],
        '–ß–µ—Ö–æ–≤': ['—á–µ—Ö–æ–≤'],
        '–û–¥–∏–Ω—Ü–æ–≤–æ': ['–æ–¥–∏–Ω—Ü–æ–≤–æ'],
        '–õ–∏–¥–∞': ['–ª–∏–¥–∞'],
        '–í–ª–∞–¥–∏–º–∏—Ä': ['–≤–ª–∞–¥–∏–º–∏—Ä'],
        '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤': ['–∞–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤'],
        '–°—Ç–∞—Ä–æ–µ –°–µ–ª–æ': ['—Å—Ç–∞—Ä–æ–µ —Å–µ–ª–æ'],
        '–õ—é–±–µ—Ä—Ü—ã': ['–ª—é–±–µ—Ä—Ü—ã'],
        '–ë–µ–ª–≥–æ—Ä–æ–¥': ['–±–µ–ª–≥–æ—Ä–æ–¥'],
        '–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥': ['–≤–µ–ª–∏–∫–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥'],
        '–ú—ã—Ç–∏—â–∏': ['–º—ã—Ç–∏—â–∏'],
        '–ê–±–∞–∫–∞–Ω': ['–∞–±–∞–∫–∞–Ω'],
        '–û—Ä–µ–Ω–±—É—Ä–≥': ['–æ—Ä–µ–Ω–±—É—Ä–≥']
    }

    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ —Å—Ç—Ä–æ–∫–∏
    for city, variants in known_cities.items():
        for variant in variants:
            if variant in text.lower():
                return city

    # –ï—Å–ª–∏ –≥–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π)
    parts = [p.strip() for p in re.split(r'[,;]', text) if p.strip()]

    if len(parts) > 1:
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å (–æ–±—ã—á–Ω–æ —Ç–∞–º –≥–æ—Ä–æ–¥)
        last_part = parts[-1]

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤
        stop_words = {
            '–ò–ü', '–¢–†–ï–í–ï–õ', '–ì–†–£–ü–ü', '–¢–£–†', '–í–û–Ø–ñ', '–ö–û–†–ê–õ', '–ê–ù–ï–ö–°', 'PAC', '–ü–ê–ö',
            'TRAVEL', 'GROUP', '–û–û–û', '–ó–ê–û', '–ê–û', 'LTD', 'CORP', 'COMPANY', 'CLUB',
            '–º.', '—É–ª.', '–ø—Ä.', '–±—É–ª—å–≤–∞—Ä', '–ø—Ä–æ—Å–ø–µ–∫—Ç', '—É–ª–∏—Ü–∞', '–¶–ï–ù–¢–†', '–û–§–ò–°', '–û–¢–î–ï–õ',
            '–§–ò–õ–ò–ê–õ', '–ê–ì–ï–ù–¢–°–¢–í–û', '–ë–Æ–†–û', '–°–ï–¢–¨', '–ö–û–ú–ü–ê–ù–ò–Ø', 'EXPERT', 'EXPERTS',
            'WORLD', 'INTERNATIONAL', 'SERVICE', 'SERVICES', '–ö–†–£–ö–õ–ê–ë', '–ê–õ–õ–ò–ù–¢–†–≠–í–ï–õ',
            '–ì–ï–†–ú–ï–°', '–°–ê–ù–≠–ö–°–ü–†–ï–°–°-–ì–ü', '–ú–ê –ú–ò–õ–¨–Ø–ù–ê', '–ö–†–£–ì–û–ó–û–†', '–ü–†–ê–ô–ú', '–≠–î–ï–ú-–°–ï–†–í–ò–°',
            '–ë–£–¢–ò–ö –ü–£–¢–ï–®–ï–°–¢–í–ò–ô', '–ê–ü –ê–†–§–ê', '–ö–†–ê–°–ö–ò –ú–ò–†–ê', '–ë–û–ù–ñ–£–†', '–ú–ï–†–ò–î–ò–ê–ù',
            '–î–ò–†–ï–ö–¢–û–†–ò–£–ú', '–†–ï–ì–ò–û–ù', '–í–û–õ–ì–ê', '–°–ò–ë–ò–†–¨', '–£–†–ê–õ', '–î–ê–õ–¨–ù–ò–ô –í–û–°–¢–û–ö'
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–æ –∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if (not any(stop_word in last_part.upper() for stop_word in stop_words) and
            len(last_part) >= 3 and
            not last_part.isdigit() and
            re.match(r'^[–ê-–Ø–Å–∞-—è—ëA-Za-z\- ]+$', last_part)):

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–±—â–∏—Ö —Å–ª–æ–≤
            common_words = {'–¢–£–†–ò–ó–ú', '–û–¢–î–´–•', '–ü–£–¢–ï–®–ï–°–¢–í–ò–ô', '–¢–£–†–û–í', '–í–û–Ø–ñ', '–¢–†–ï–í–ï–õ'}
            if not any(word in last_part.upper() for word in common_words):
                return last_part.strip()

    return '–î—Ä—É–≥–æ–π'

def fill_missing_buyer_names(df):
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ –≤ buyer_name: –ö–õ–ò–ï–ù–¢–°–ö–ò–ô –ó–ê–õ –∏–ª–∏ '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
    if 'buyer_department' not in df.columns or 'buyer_name' not in df.columns:
        return df
    
    #  –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º –ö–õ–ò–ï–ù–¢–°–ö–ò–ô –ó–ê–õ
    mask_client_hall = (
        (df['buyer_department'] == '–ö–õ–ò–ï–ù–¢–°–ö–ò–ô –ó–ê–õ') & 
        (df['buyer_name'].isna() | (df['buyer_name'] == ''))
    )
    count_client_hall = mask_client_hall.sum()
    df.loc[mask_client_hall, 'buyer_name'] = '–ö–õ–ò–ï–ù–¢–°–ö–ò–ô –ó–ê–õ'
    
    # –ó–∞—Ç–µ–º –∑–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏
    mask_other = df['buyer_name'].isna() | (df['buyer_name'] == '')
    count_other = mask_other.sum()
    df.loc[mask_other, 'buyer_name'] = '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'
    
    # —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if count_client_hall > 0:
        print(f" –ó–∞–ø–æ–ª–Ω–µ–Ω–æ '–ö–õ–ò–ï–ù–¢–°–ö–ò–ô –ó–ê–õ': {count_client_hall} –∑–∞–ø–∏—Å–µ–π")
    if count_other > 0:
        print(f" –ó–∞–ø–æ–ª–Ω–µ–Ω–æ '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω': {count_other} –∑–∞–ø–∏—Å–µ–π")
    if count_client_hall == 0 and count_other == 0:
        print(" –ü—Ä–æ–ø—É—Å–∫–æ–≤ –≤ buyer_name –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    return df



def enrich_data(df):
    """–î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏"""

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã
    df['creation_date'] = pd.to_datetime(df['creation_date'], errors='coerce')
    df['checkin_date'] = pd.to_datetime(df['checkin_date'], errors='coerce')

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç –≤ —Ä—É–±–ª–∏
    print("üí± –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç –≤ —Ä—É–±–ª–∏...")
    rates_df = get_currency_rates()
    if rates_df is not None:
        df['amount_rub'] = df.apply(lambda row: convert_to_rub(row, rates_df), axis=1)
        print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {len(df)} –∑–∞–ø–∏—Å–µ–π")
    else:
        print("‚ö†Ô∏è –ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é")
        df['amount_rub'] = df['amount_to_pay']  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—É–º–º—ã

     # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    if 'payment' in df.columns and 'amount_to_pay' in df.columns:
        df['payment_percentage'] = (df['payment'] / df['amount_to_pay'] * 100).round(2)
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        df['payment_percentage'] = df['payment_percentage'].replace([np.inf, -np.inf], 0)

    if 'checkin_date' in df.columns and 'creation_date' in df.columns:
        df['days_until_checkin'] = (df['checkin_date'] - df['creation_date']).dt.days
        df['days_until_checkin'] = df['days_until_checkin'].fillna(0)

    if 'country' in df.columns:

        cruise_agents = df.loc[df['country'].astype(str).str.lower().str.contains('–∫—Ä—É–∏–∑'), 'buyer_name'].unique()

        df['is_cruise_seller'] = df['buyer_name'].apply(lambda x: 1 if x in cruise_agents else 0)

    if 'creation_date' in df.columns:
        df['creation_month'] = df['creation_date'].dt.month

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–≥–∏–æ–Ω
    if 'buyer_name' in df.columns:
        df['region'] = df['buyer_name'].apply(extract_region)

    return df



def upload_to_sheets(df, credentials_file='/home/vulcan4ik/dashboard-cruise-app/credentials.json', spreadsheet_name=None):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Google Sheets —Å fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    –í–°–ï–ì–î–ê —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç CSV —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    # –°–ù–ê–ß–ê–õ–ê –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
    csv_filename = save_data_locally(df)

    # –ü–û–¢–û–ú –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Sheets (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    print("\nüì§ –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Sheets...")

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ credentials
        if not os.path.exists(credentials_file):
            print(f"‚ö†Ô∏è –§–∞–π–ª credentials –Ω–µ –Ω–∞–π–¥–µ–Ω: {credentials_file}")
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤ Google Sheets")
            return csv_filename

        print(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è credentials —Ñ–∞–π–ª: {credentials_file}")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Sheets
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_file(credentials_file, scopes=scope)
        client = gspread.authorize(creds)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –∏–º—è —Ç–∞–±–ª–∏—Ü—ã
        SPREADSHEET_NAME = "Cruise_Analytics_Dashboard"

        try:
            # –ü—Ä–æ–±—É–µ–º –æ—Ç–∫—Ä—ã—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü—É
            spreadsheet = client.open(SPREADSHEET_NAME)
            print(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü—É: {SPREADSHEET_NAME}")
        except gspread.SpreadsheetNotFound:
            # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            spreadsheet = client.create(SPREADSHEET_NAME)
            print(f"üìä –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞: {SPREADSHEET_NAME}")

        worksheet = spreadsheet.get_worksheet(0)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = [df.columns.tolist()] + df.values.tolist()

        # –û—á–∏—â–∞–µ–º –ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        worksheet.clear()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        worksheet.update('A1', data)

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø
        spreadsheet.share(None, perm_type='anyone', role='reader')

        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Google Sheets!")
        print(f"üìä –°—Å—ã–ª–∫–∞: {spreadsheet.url}")

        # –í–ê–ñ–ù–û: –í—Å—ë —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º—è CSV —Ñ–∞–π–ª–∞
        return csv_filename

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Sheets: {str(e)}")
        print("‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –ª–æ–∫–∞–ª—å–Ω—ã–º CSV —Ñ–∞–π–ª–æ–º")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
        return csv_filename


def save_data_locally(df):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ª–æ–∫–∞–ª—å–Ω–æ"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        results_dir = '/home/vulcan4ik/dashboard-cruise-app/results'
        os.makedirs(results_dir, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º DataFrame
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_filename = f"processed_{timestamp}.csv"
        csv_path = os.path.join(results_dir, csv_filename)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8 —Å BOM –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è –≤ Excel
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ!")
        print(f"üìä –§–∞–π–ª: {csv_path}")
        print(f"üì¶ –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ /download/
        return csv_filename

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
        raise


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
def process_and_upload(file_path, credentials_file='/home/vulcan4ik/dashboard-cruise-app/credentials.json'):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    """
    print("\n" + "="*50)
    print("üöÄ –ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•")
    print("="*50 + "\n")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    processed_df = process_data(file_path)

    print("\n" + "="*50)
    print("üì§ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*50 + "\n")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ –∏ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Sheets
    csv_filename = upload_to_sheets(processed_df, credentials_file)

    print("\n" + "="*50)
    print("‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("="*50 + "\n")

    return processed_df, csv_filename

